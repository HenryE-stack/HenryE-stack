### Hiüëã, I'm Henry, a Data Engineer at Cognizant

- Currently working as an integrator of the [AVEVA PI System](https://github.com/HenryE-stack/HenryE-stack/assets/76691441/a9a9cd1e-ebe5-4ef5-8362-6ef9aa4a14cb) üñ•Ô∏è.<br>
- Have over three years experience in pharmaceutical and medical device manufacturing üíä.<br>
- Obtained a Bachelors in Electronic and Computer Engineering ‚öôÔ∏è.<br>
- Currently in the progress of completing a Masters in Data Anayltics üìä.<br>
- Also learning Databricks and AWS üìó.<br>


Check out my LinkedIn: https://www.linkedin.com/in/henry-egbulam/

Certifications: https://github.com/HenryE-stack/Certifications<br>


## Academic Projects

### Netflix Business Intelligence System - Business Intelligence and Business Analytics Continuous Assessment - [Repo](https://github.com/HenryE-stack/BI-BA_Netflix_Project/tree/main)<br>
**Project Summary**<br>
This project involved building a Business Intelligence system to enhance Netflix's customer engagement and profitability.<br>
Real financial data and mock user data were cleaned, transformed, and integrated into a PostgreSQL database.<br>
A series of interactive Power BI dashboards were then developed to visualize key business metrics for management, covering membership growth, regional financial performance, and customer experience.<br>

**Tools Used**<br>
- Data Storage & Management: PostgreSQL, PGAdmin 
- Data Integration & Transformation: Python, Microsoft Excel 
- BI & Visualization: Power BI 
- Version Control & Collaboration: GitHub, Microsoft Teams 
- Containerization: Docker

### Food Environment Atlas & National Obesity by State - Data Analysis - [Repo](https://github.com/HenryE-stack/GroupE_DataProject)
**Project Summary**<br>
This project demonstrates an automated ETL (Extract-Transform-Load) pipeline to create a unified data repository on nutrition. It combines the U.S. Food Environment Atlas and National Obesity by State datasets.<br>
The pipeline, orchestrated by Dagster , extracts data from a web API and CSV files, loads it into MongoDB for staging , and performs transformations using Python and Pandas.<br>
A key challenge was cleaning and standardizing the 'State' field for merging.<br>
The final, consolidated dataset is loaded into a PostgreSQL database , with Bokeh used to create visualizations exploring the relationships between food environments and health outcomes. <br>

**Tools Used**<br>
- Data Orchestration: Dagster 
- Programming & Environment: Python, Conda 
- Databases: PostgreSQL (relational store), MongoDB (document store) 
- Containerization: Docker 
- Visualization: Bokeh 
- Database Management: PGAdmin

